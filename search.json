[
  {
    "objectID": "strategies.html",
    "href": "strategies.html",
    "title": "Strategies",
    "section": "",
    "text": "This app won’t make your work completely MAGA-proof, but at least it should help you get past automated keyword searchers. Once you run your document through the screener and find your matching keywords, just change the targeted words. Here are some strategies:\n\nUse synonyms: Replace potentially flagged words with their synonyms (e.g., “inclusive” → “welcoming”).\nAdd extra letters: Insert additional letters in words that don’t change pronunciation (e.g., “divverse”).\nUse numbers: Replace letters with numbers, e.g. “o” with “0”, capital “I” with “1”.\nIntentional misspellings: Slightly misspell words while keeping them recognizable (e.g., “equaty” instead of “equity”).\nAdd invisible characters: Insert zero-width spaces or other invisible Unicode characters between letters.\nCompound splitting: Break terms into component parts with hyphens or spaces (e.g., “social-justice” → “social fairness”).\nUse circumlocution: Describe the concept rather than using the term directly.\nHomophone substitution: Use words that sound the same but are spelled differently.\nUse metaphors: Replace direct terms with metaphorical language that conveys similar meaning. (e.g., “leveling the playing field” instead of “equity”).\nAdd diacritics or accented characters: Modify letters slightly while keeping them recognizable (e.g., “ĕquity” instead of “equity”).\nUse homoglyphs: Replace letters with visually similar characters from other alphabets (e.g., “а” → “a” from Cyrillic, “α” → “а” from Greek).\nUse indirect references: Instead of explicitly naming frameworks, emphasize methodology or intended results (e.g., “improving participatory outcomes” instead of “democratizing institutions”)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This tool allows you to analyze documents for MAGA-targeted keywords. You can also upload your own CSV file of keywords. It is intended to be used to help identify words that might get screened by an entity (e.g., the federal government) so you can modify your language accordingly. Just upload a document, and the app will count occurrences of the keywords.\nSupported File Types:\n\nWord Documents: .docx, .doc\nPDF Files: .pdf\nText Files: .txt\nSpreadsheets: .csv, .xlsx\nWeb Documents: .html, .htm, .xml\nOther: .rtf, .json\n\n\nHow It Works\nThe analyzer extracts text from your document and searches for keywords from our predefined list. It then counts how many times each keyword appears in your document. That’s all - it’s pretty simple.\nAll of the calculations run locally in your web browser using web assembly. Whatever you upload isn’t stored or sent anywhere for processing, so you can upload even sensitive documents without worry. You can also run it locally on your computer if you want.\nThis site was built entirely using open-source tools. It uses the Quarto publishing system to build the website, the R programming language for logic, and the shiny web application framework to implement the R code, leveraging shinylive Quarto extension to run the whole thing in the browser as a static web page (thanks to @coatless for posting such a great tutorial on how to set this up). The site itself is hosted on GitHub pages, and the source code can be found at https://github.com/jhelvy/magaScreener.\n\n\nLocally Running the App\nYou can run the app on your local machine without even being connected to the internet. To do so, follow these steps:\nInstall stuff\n\nInstall R\nInstall RStudio Desktop\nInstall Quarto\n\nDownload and run the app\nOnce everything is installed, download the source code, then unzip the file and open the \"magaScreener.Rproj\" file. This should open RStudio.\nOnce open, click on the \"index.qmd\" file, then click the “render” button at the top of the RStudio application (it has a little blue arrow next to it). This should open a web browser from where you can then use the application.\nAlternatively you can click on the \"Terminal\" window and run the following command:\n\nquarto preview"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAGA Keyword Screener",
    "section": "",
    "text": "This can take ~30s to load…just leave the window open until it loads Also you don’t have to restart it to upload another doc - it will just start over with each doc\n\n#| standalone: true\n#| viewerHeight: 800\n\nlibrary(shiny)\nlibrary(readtext)\nlibrary(stringr)\nlibrary(DT)\nlibrary(bslib)\nlibrary(shinyjs)  # Add shinyjs for JavaScript interactions\nlibrary(jsonlite) # For JSON handling\nlibrary(xml2)     # For XML handling\nlibrary(readxl)   # For Excel file handling\n\n# Function to load keywords from GitHub repository\nload_github_keywords &lt;- function() {\n  # URL to the raw keywords.csv file in the GitHub repository\n  github_url &lt;- \"https://raw.githubusercontent.com/jhelvy/magaScreener/main/keywords.csv\"\n  \n  tryCatch({\n    # Read the CSV file directly from GitHub using read.csv\n    keywords_df &lt;- read.csv(github_url, stringsAsFactors = FALSE)\n    \n    # Extract the keywords column\n    if (\"words\" %in% colnames(keywords_df)) {\n      return(keywords_df$words)\n    } else {\n      # If column name is different, take the first column\n      return(keywords_df[[1]])\n    }\n  }, error = function(e) {\n    # If GitHub fetch fails, use the fallback hardcoded keywords\n    warning(paste(\"Error fetching keywords from GitHub:\", e$message, \"Using fallback keywords.\"))\n    return(get_fallback_keywords())\n  })\n}\n\n# Fallback hardcoded keywords (original list)\nget_fallback_keywords &lt;- function() {\n  return(c(\"accessible\", \"activism\", \"activists\", \"advocacy\", \"advocate\", \"advocates\", \"affirming care\", \"all-inclusive\", \"allyship\", \"anti-racism\", \"antiracist\", \"assigned at birth\", \"assigned female at birth\", \"assigned male at birth\", \"assigned male\", \"assigned female\", \"at risk\", \"barrier\", \"barriers\", \"belong\", \"bias\", \"biased\", \"biased toward\", \"biases\", \"biases towards\", \"biologically female\", \"biologically male\", \"BIPOC\", \"Black\", \"breastfeed\", \"breastfeed + people\", \"breastfeed + person\", \"chestfeed\", \"chestfeed + people\", \"chestfeed + person\", \"clean energy\", \"climate crisis\", \"climate science\", \"commercial sex worker\", \"community diversity\", \"community equity\", \"confirmation bias\", \"cultural competence\", \"cultural differences\", \"cultural heritage\", \"cultural sensitivity\", \"culturally appropriate\", \"culturally responsive\", \"DEI\", \"DEIA\", \"DEIAB\", \"DEIJ\", \"disabilities\", \"disability\", \"discriminated\", \"discrimination\", \"discriminatory\", \"disparity\", \"diverse\", \"diverse backgrounds\", \"diverse communities\", \"diverse community\", \"diverse group\", \"diverse groups\", \"diversified\", \"diversify\", \"diversifying\", \"diversity\", \"enhance the diversity\", \"enhancing diversity\", \"environmental quality\", \"equal opportunity\", \"equality\", \"equitable\", \"equitableness\", \"equity\", \"ethnicity\", \"excluded\", \"exclusion\", \"expression\", \"female\", \"females\", \"feminism\", \"fostering inclusivity\", \"GBV\", \"gender\", \"gender based\", \"gender based violence\", \"gender diversity\", \"gender identity\", \"gender ideology\", \"gender-affirming care\", \"genders\", \"Gulf of Mexico\", \"hate speech\", \"health disparity\", \"health equity\", \"hispanic minority\", \"historically\", \"identity\", \"immigrants\", \"implicit bias\", \"implicit biases\", \"inclusion\", \"inclusive\", \"inclusive leadership\", \"inclusiveness\", \"inclusivity\", \"increase diversity\", \"increase the diversity\", \"indigenous community\", \"inequalities\", \"inequality\", \"inequitable\", \"inequities\", \"inequity\", \"injustice\", \"institutional\", \"intersectional\", \"intersectionality\", \"key groups\", \"key people\", \"key populations\", \"Latinx\", \"LGBT\", \"LGBTQ\", \"marginalize\", \"marginalized\", \"men who have sex with men\", \"mental health\", \"minorities\", \"minority\", \"most risk\", \"MSM\", \"multicultural\", \"Mx\", \"Native American\", \"non-binary\", \"nonbinary\", \"oppression\", \"oppressive\", \"orientation\", \"uterus\", \"people + uterus\", \"people-centered care\", \"person-centered\", \"person-centered care\", \"polarization\", \"political\", \"pollution\", \"pregnant people\", \"pregnant person\", \"pregnant persons\", \"prejudice\", \"privilege\", \"privileges\", \"promote diversity\", \"promoting diversity\", \"pronoun\", \"pronouns\", \"prostitute\", \"race\", \"race and ethnicity\", \"racial\", \"racial diversity\", \"racial identity\", \"racial inequality\", \"racial justice\", \"racially\", \"racism\", \"segregation\", \"sense of belonging\", \"sex\", \"sexual preferences\", \"sexuality\", \"social justice\", \"sociocultural\", \"socioeconomic\", \"status\", \"stereotype\", \"stereotypes\", \"systemic\", \"systemically\", \"they/them\", \"trans\", \"transgender\", \"transsexual\", \"trauma\", \"traumatic\", \"tribal\", \"unconscious bias\", \"underappreciated\", \"underprivileged\", \"underrepresentation\", \"underrepresented\", \"underserved\", \"undervalued\", \"victim\", \"victims\", \"vulnerable populations\", \"woke\", \"women\", \"women and underrepresented\"))\n}\n\n# Custom JS for PDF handling - optimized for analysis with explicit button trigger\njs_code &lt;- \"\n// Function to handle PDF extraction using PDF.js\nfunction extractPdfText(fileInput) {\n  const file = fileInput.files[0];\n  if (!file || file.type !== 'application/pdf') {\n    return;\n  }\n  \n  // Create a URL for the file\n  const fileURL = URL.createObjectURL(file);\n  \n  // Set loading state immediately\n  Shiny.setInputValue('pdf_loading', true);\n  \n  // Load PDF.js from CDN if not already loaded\n  if (typeof pdfjsLib === 'undefined') {\n    // Set worker source (required for PDF.js)\n    const script = document.createElement('script');\n    script.src = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js';\n    script.onload = function() {\n      pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';\n      processPdf(fileURL);\n    };\n    document.head.appendChild(script);\n  } else {\n    processPdf(fileURL);\n  }\n  \n  // Function to process the PDF\n  function processPdf(url) {\n    pdfjsLib.getDocument(url).promise.then(function(pdf) {\n      let textContent = '';\n      let pendingPages = pdf.numPages;\n      \n      // Update progress in UI with total pages info\n      Shiny.setInputValue('pdf_progress', { current: 0, total: pendingPages });\n      \n      // Extract text from each page\n      for (let i = 1; i &lt;= pdf.numPages; i++) {\n        pdf.getPage(i).then(function(page) {\n          page.getTextContent().then(function(content) {\n            const strings = content.items.map(item =&gt; item.str);\n            textContent += strings.join(' ') + '\\\\n';\n            \n            // Update progress\n            Shiny.setInputValue('pdf_progress', { \n              current: pdf.numPages - pendingPages + 1, \n              total: pdf.numPages \n            });\n            \n            // Check if all pages are processed\n            pendingPages--;\n            if (pendingPages === 0) {\n              // Send the extracted text back to Shiny\n              Shiny.setInputValue('pdf_text', textContent);\n              Shiny.setInputValue('pdf_loading', false);\n              \n              // Clean up\n              URL.revokeObjectURL(url);\n            }\n          });\n        });\n      }\n    }).catch(function(error) {\n      console.error('Error loading PDF:', error);\n      Shiny.setInputValue('pdf_error', error.message);\n      Shiny.setInputValue('pdf_loading', false);\n      URL.revokeObjectURL(url);\n    });\n  }\n}\n\n// Initialize PDF handling when document input changes\n$(document).on('change', '#document', function(e) {\n  // Clear previous values \n  Shiny.setInputValue('pdf_error', null);\n  Shiny.setInputValue('pdf_text', null);\n  \n  const file = this.files[0];\n  if (file && file.type === 'application/pdf') {\n    // For PDFs, extract text using PDF.js\n    extractPdfText(this);\n  } else {\n    // For non-PDFs, ensure pdf_loading is false so analysis can proceed\n    Shiny.setInputValue('pdf_loading', false);\n  }\n});\n\"\n\nui &lt;- page_fluid(\n  # Theme with simplified layout\n  theme = bs_theme(\n    bootswatch = \"flatly\",\n    primary = \"#2c3e50\",\n    \"navbar-bg\" = \"#2c3e50\"\n  ),\n  \n  # Include shinyjs\n  shinyjs::useShinyjs(),\n  \n  # Include custom JavaScript and CSS for better layout\n  tags$head(\n    tags$script(HTML(js_code)),\n    tags$style(HTML(\"\n      /* Simplified styles with no nested cards */\n      body {\n        padding: 15px;\n      }\n      \n      .document-info {\n        background-color: #f8f9fa;\n        padding: 15px;\n        border-radius: 5px;\n        font-family: monospace;\n        margin-bottom: 20px;\n      }\n      \n      .section-header {\n        font-weight: bold;\n        font-size: 1.2rem;\n        margin-top: 20px;\n        margin-bottom: 15px;\n        padding-bottom: 5px;\n        border-bottom: 1px solid #e9ecef;\n      }\n      \n      /* Make the table more compact and readable */\n      .dataTables_wrapper {\n        padding: 10px 0;\n      }\n      \n      /* Snarky message styling */\n      .snarky-message {\n        font-size: 1.1rem;\n        padding: 15px;\n        margin: 20px 0;\n        border-radius: 5px;\n        font-weight: bold;\n      }\n      \n      .snarky-warning {\n        background-color: #f8d7da;\n        color: #721c24;\n        border: 1px solid #f5c6cb;\n      }\n      \n      .snarky-success {\n        background-color: #d4edda;\n        color: #155724;\n        border: 1px solid #c3e6cb;\n      }\n      \n      /* Button styling */\n      .action-button {\n        margin-top: 10px;\n      }\n      \n      /* Layout adjustments */\n      .col-sm-4 {\n        background-color: #f8f9fa;\n        padding: 20px;\n        border-radius: 5px;\n      }\n      \n      /* Add space between columns */\n      .col-sm-8 {\n        padding-left: 30px;\n      }\n      \n      /* Keyword source section styling */\n      .keyword-source-section {\n        margin-top: 20px;\n        padding-top: 15px;\n        border-top: 1px solid #e9ecef;\n      }\n    \"))\n  ),\n  \n  # Layout with sidebar and main content in a fluidRow\n  fluidRow(\n    # Sidebar panel\n    column(\n      width = 4,\n      h4(\"Document Upload\", class = \"mb-3\"),\n      fileInput(\"document\", \"Choose Document\", \n                accept = c(\".docx\", \".doc\", \".pdf\", \".txt\", \".csv\", \".html\", \n                           \".htm\", \".rtf\", \".xml\", \".json\", \".xlsx\", \".xls\")),\n      \n      # PDF processing status (conditionally shown)\n      conditionalPanel(\n        condition = \"input.pdf_loading == true\",\n        div(\n          class = \"alert alert-info\",\n          \"Processing PDF... This may take a moment.\",\n          tags$div(\n            class = \"progress mt-2\",\n            tags$div(\n              id = \"pdf-progress-bar\",\n              class = \"progress-bar progress-bar-striped progress-bar-animated\",\n              role = \"progressbar\",\n              style = \"width: 0%\"\n            )\n          )\n        )\n      ),\n      \n      # Keyword source selection section\n      div(\n        class = \"keyword-source-section\",\n        h4(\"Keyword Source\", class = \"mb-3\"),\n        radioButtons(\"keyword_source\", \"Select Keyword Source:\",\n                    choices = list(\n                      \"Default\" = \"github\",\n                      \"Upload Custom Keywords\" = \"custom\"\n                    ),\n                    selected = \"github\"),\n        \n        # Custom keywords file upload (conditionally shown)\n        conditionalPanel(\n          condition = \"input.keyword_source == 'custom'\",\n          fileInput(\"custom_keywords\", \"Upload Keywords CSV\",\n                   accept = c(\".csv\")),\n          tags$p(class = \"text-muted\", \"CSV file should have a header row with 'words' column containing keywords.\")\n        )\n      ),\n      \n      # Added analyze button for manual analysis triggering\n      actionButton(\"analyze_btn\", \"Analyze Document\", \n                   class = \"btn-primary btn-block mt-3\"),\n      \n      hr(),\n      \n      tags$p(\"Supported formats: Word (.docx, .doc), PDF, Text, CSV, HTML, XML, JSON, Excel (.xlsx, .xls), RTF\"),\n      tags$p(class = \"text-muted\", \"Click 'Analyze Document' after uploading to begin analysis.\")\n    ),\n    \n    # Main content\n    column(\n      width = 8,\n      # Status message\n      uiOutput(\"status_message\"),\n      \n      # Document information section\n      conditionalPanel(\n        condition = \"output.document_analyzed == true\",\n        \n        h3(\"Analysis Results\", class = \"section-header\"),\n        \n        # Document basic info with better styling\n        h4(\"Document Information\", class = \"section-header\"),\n        div(\n          class = \"document-info\",\n          verbatimTextOutput(\"document_info\")\n        ),\n        \n        # Snarky message output\n        htmlOutput(\"snarky_message\"),\n        \n        # Keywords table - only shown if keywords are found\n        conditionalPanel(\n          condition = \"output.has_keywords == true\",\n          h4(\"Keywords Found\", class = \"section-header\"),\n          DT::dataTableOutput(\"keyword_table\")\n        )\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  \n  # JavaScript to update progress bar\n  observe({\n    if (!is.null(input$pdf_progress)) {\n      progress &lt;- input$pdf_progress\n      percentage &lt;- round((progress$current / progress$total) * 100)\n      shinyjs::runjs(sprintf(\n        \"$('#pdf-progress-bar').css('width', '%s%%').attr('aria-valuenow', %s)\",\n        percentage, percentage\n      ))\n    }\n  })\n  \n  # Reactive values to store analysis results\n  results &lt;- reactiveVal(NULL)\n  \n  # Store PDF text when it becomes available\n  pdf_text &lt;- reactiveVal(NULL)\n  observe({\n    if (!is.null(input$pdf_text)) {\n      pdf_text(input$pdf_text)\n    }\n  })\n  \n  # Reactive value to store current keywords\n  current_keywords &lt;- reactiveVal(NULL)\n  \n  # Initialize keywords from GitHub when app starts\n  observe({\n    # Only load if current_keywords is NULL (first load)\n    if (is.null(current_keywords())) {\n      github_keywords &lt;- load_github_keywords()\n      current_keywords(github_keywords)\n    }\n  })\n  \n  # Update keywords when source changes or custom file is uploaded\n  observe({\n    # Reset when source changes\n    if (input$keyword_source == \"github\") {\n      github_keywords &lt;- load_github_keywords()\n      current_keywords(github_keywords)\n    } else if (input$keyword_source == \"custom\" && !is.null(input$custom_keywords)) {\n      # Read custom keywords from uploaded file\n      tryCatch({\n        custom_file &lt;- input$custom_keywords\n        custom_keywords_df &lt;- read.csv(custom_file$datapath, stringsAsFactors = FALSE)\n        \n        # Extract keywords from the dataframe\n        if (\"words\" %in% colnames(custom_keywords_df)) {\n          custom_keywords &lt;- custom_keywords_df$words\n        } else {\n          # If column name is different, take the first column\n          custom_keywords &lt;- custom_keywords_df[[1]]\n        }\n        \n        # Update current keywords\n        current_keywords(custom_keywords)\n      }, error = function(e) {\n        # If error occurs, show a notification and use GitHub keywords\n        showNotification(\n          paste(\"Error reading custom keywords:\", e$message, \"Using default keywords instead.\"),\n          type = \"error\",\n          duration = 10\n        )\n        github_keywords &lt;- load_github_keywords()\n        current_keywords(github_keywords)\n      })\n    }\n  })\n  \n  # Output indicator for whether document has been analyzed\n  output$document_analyzed &lt;- reactive({\n    !is.null(results())\n  })\n  outputOptions(output, \"document_analyzed\", suspendWhenHidden = FALSE)\n  \n  # Output indicator for whether keywords were found\n  output$has_keywords &lt;- reactive({\n    !is.null(results()) && length(results()$keywords_found) &gt; 0\n  })\n  outputOptions(output, \"has_keywords\", suspendWhenHidden = FALSE)\n  \n  # Status message - updated for button-triggered analysis\n  output$status_message &lt;- renderUI({\n    if (!is.null(input$pdf_error)) {\n      return(div(class = \"alert alert-danger\", \n                 \"PDF Error: \", input$pdf_error))\n    }\n    \n    if (!is.null(input$pdf_loading) && input$pdf_loading) {\n      return(div(class = \"alert alert-info\", \n                 \"Processing PDF... Please wait.\"))\n    }\n    \n    if (is.null(results())) {\n      if (is.null(input$document)) {\n        return(div(class = \"alert alert-info\", \n                   \"Please upload a document and click 'Analyze Document' to begin.\"))\n      } else {\n        return(div(class = \"alert alert-info\", \n                   \"Document uploaded. Click 'Analyze Document' to begin analysis.\"))\n      }\n    } else if (!is.null(results()$error)) {\n      return(div(class = \"alert alert-danger\", \n                 \"Error: \", results()$error))\n    } else {\n      return(div(class = \"alert alert-success\", \n                 \"Analysis complete!\"))\n    }\n  })\n  \n  # Function to extract text from document with improved file type support\n  extract_text &lt;- function(file_path) {\n    # Check if we have PDF text from JavaScript\n    if (!is.null(input$document) && \n        tolower(tools::file_ext(input$document$name)) == \"pdf\" && \n        !is.null(pdf_text())) {\n      return(pdf_text())\n    }\n    \n    # Get file extension\n    file_ext &lt;- tolower(tools::file_ext(file_path))\n    \n    # Handle each file type appropriately\n    tryCatch({\n      if (file_ext == \"txt\") {\n        # Plain text files\n        text &lt;- readLines(file_path, warn = FALSE)\n        return(paste(text, collapse = \"\\n\"))\n        \n      } else if (file_ext %in% c(\"csv\")) {\n        # CSV files - improved handling\n        df &lt;- read.csv(file_path, stringsAsFactors = FALSE)\n        # Convert all columns to character for better text extraction\n        df[] &lt;- lapply(df, as.character)\n        # Combine all cells into a single text string\n        text &lt;- paste(unlist(df), collapse = \" \")\n        return(text)\n        \n      } else if (file_ext %in% c(\"xlsx\", \"xls\")) {\n        # Excel files\n        sheets &lt;- readxl::excel_sheets(file_path)\n        all_text &lt;- character(0)\n        \n        for (sheet in sheets) {\n          df &lt;- readxl::read_excel(file_path, sheet = sheet)\n          # Convert to character\n          df[] &lt;- lapply(df, as.character)\n          # Add sheet content\n          all_text &lt;- c(all_text, paste(\"Sheet:\", sheet))\n          all_text &lt;- c(all_text, paste(unlist(df), collapse = \" \"))\n        }\n        \n        return(paste(all_text, collapse = \"\\n\"))\n        \n      } else if (file_ext == \"json\") {\n        # JSON files\n        json_data &lt;- jsonlite::fromJSON(file_path)\n        # Recursively extract all values from JSON\n        extract_values &lt;- function(obj) {\n          if (is.list(obj)) {\n            values &lt;- unlist(lapply(obj, extract_values))\n            return(paste(values, collapse = \" \"))\n          } else if (is.data.frame(obj)) {\n            # Convert data frame to character\n            obj[] &lt;- lapply(obj, as.character)\n            return(paste(unlist(obj), collapse = \" \"))\n          } else if (is.vector(obj) && !is.character(obj)) {\n            return(paste(obj, collapse = \" \"))\n          } else {\n            return(obj)\n          }\n        }\n        \n        text &lt;- extract_values(json_data)\n        return(text)\n        \n      } else if (file_ext == \"xml\") {\n        # XML files\n        xml_data &lt;- xml2::read_xml(file_path)\n        # Extract all text content from XML nodes\n        nodes &lt;- xml2::xml_find_all(xml_data, \"//text()\")\n        text &lt;- xml2::xml_text(nodes)\n        return(paste(text, collapse = \" \"))\n        \n      } else if (file_ext %in% c(\"html\", \"htm\")) {\n        # HTML files - improved handling\n        html_content &lt;- xml2::read_html(file_path)\n        nodes &lt;- xml2::xml_find_all(html_content, \"//text()\")\n        text &lt;- xml2::xml_text(nodes)\n        return(paste(text, collapse = \" \"))\n        \n      } else {\n        # Use readtext as a fallback for other formats (docx, rtf, etc.)\n        text_data &lt;- readtext::readtext(file_path)\n        return(text_data$text)\n      }\n    }, error = function(e) {\n      # Log the error\n      warning(paste(\"Error extracting text from document:\", e$message))\n      return(\"\")\n    })\n  }\n  \n  # Function to find keywords in text\n  find_keywords &lt;- function(text, keywords) {\n    text_lower &lt;- tolower(text)\n    found_keywords &lt;- character(0)\n    keyword_counts &lt;- numeric(0)\n    \n    for (keyword in keywords) {\n      # Use word boundaries to match whole words\n      pattern &lt;- paste0(\"\\\\b\", tolower(keyword), \"\\\\b\")\n      matches &lt;- str_count(text_lower, pattern)\n      \n      if (matches &gt; 0) {\n        found_keywords &lt;- c(found_keywords, keyword)\n        keyword_counts &lt;- c(keyword_counts, matches)\n      }\n    }\n    \n    # Create a named vector of counts\n    names(keyword_counts) &lt;- found_keywords\n    \n    return(list(\n      keywords = found_keywords,\n      counts = keyword_counts\n    ))\n  }\n  \n  # Analyze document when button is clicked\n  observeEvent(input$analyze_btn, {\n    # Ensure a document is uploaded\n    if (is.null(input$document)) {\n      results(list(error = \"Please upload a document first.\"))\n      return()\n    }\n    \n    # Check if PDF is still loading\n    if (!is.null(input$pdf_loading) && input$pdf_loading) {\n      results(list(error = \"PDF is still processing. Please wait.\"))\n      return()\n    }\n    \n    # Check for PDF errors\n    if (!is.null(input$pdf_error)) {\n      results(list(error = paste(\"PDF Error:\", input$pdf_error)))\n      return()\n    }\n    \n    # Check if we have keywords\n    if (is.null(current_keywords()) || length(current_keywords()) == 0) {\n      results(list(error = \"No keywords available for analysis. Please check keyword source.\"))\n      return()\n    }\n    \n    # Extract document info\n    doc_path &lt;- input$document$datapath\n    doc_name &lt;- input$document$name\n    file_type &lt;- tolower(tools::file_ext(doc_name))\n    \n    # Show progress indicator for large files\n    withProgress(message = 'Analyzing document...', value = 0.2, {\n      # Extract text from document\n      text &lt;- extract_text(doc_path)\n      \n      if (text == \"\") {\n        results(list(error = \"Failed to extract text from the document. The file format may not be fully supported.\"))\n        return()\n      }\n      \n      setProgress(value = 0.5, detail = \"Searching for keywords...\")\n      \n      # Find keywords in the text using current keywords\n      keyword_results &lt;- find_keywords(text, current_keywords())\n      \n      # Calculate word and character counts\n      words &lt;- unlist(strsplit(text, \"\\\\s+\"))\n      words &lt;- words[words != \"\"] # Remove empty strings\n      \n      setProgress(value = 0.9, detail = \"Finalizing results...\")\n      \n      # Store the results\n      results(list(\n        document_name = doc_name,\n        file_type = file_type,\n        text = text,\n        total_words = length(words),\n        total_chars = nchar(text),\n        keywords_found = keyword_results$keywords,\n        keyword_counts = keyword_results$counts,\n        keyword_source = input$keyword_source,\n        error = NULL\n      ))\n    })\n  })\n  \n  # Reset PDF text when new file is uploaded\n  observeEvent(input$document, {\n    pdf_text(NULL)\n    # Do NOT reset results automatically when a new file is uploaded\n    # This allows users to explicitly trigger analysis with the button\n  })\n  \n  # Output: Document info - simplified to just the basics\n  output$document_info &lt;- renderText({\n    if (is.null(results())) return(\"\")\n    \n    # Add keyword source information\n    keyword_source_info &lt;- if (results()$keyword_source == \"github\") {\n      \"GitHub Repository\"\n    } else {\n      \"Custom Upload\"\n    }\n    \n    paste0(\n      \"File Name: \", results()$document_name, \"\\n\",\n      \"File Type: \", toupper(results()$file_type), \"\\n\",\n      \"Word Count: \", format(results()$total_words, big.mark = \",\"), \"\\n\",\n      \"Keyword Source: \", keyword_source_info, \"\\n\",\n      \"Analysis Date: \", format(Sys.time(), \"%Y-%m-%d %H:%M:%S\")\n    )\n  })\n  \n  # Snarky messages - choose randomly from a set for each case\n  output$snarky_message &lt;- renderUI({\n    if (is.null(results())) return(NULL)\n\n  # Snarky messages for when keywords are found\n    warning_messages &lt;- c(\n      \"Uh oh, looks like your document has some words on the naughty list - no first amendment rights for you!\",\n      \"ALERT! Your document contains language that may cause conservative fainting spells!\",\n      \"WARNING: Potentially woke content detected! Hide your children!\",\n      \"Potentially woke language detected! Your document might cause pearl-clutching!\",\n      \"Snowflake trigger warning: Your document contains words that might make Tucker Carlson cry!\"\n    )\n    \n    # Snarky messages for when no keywords are found\n    success_messages &lt;- c(\n      \"Congratulations! Your document is free of scary words like \\\"gender\\\" that trigger the MAGA mind.\",\n      \"Good news! Nothing in your document will upset Fox News viewers!\",\n      \"You're safe! No words that might cause conservative heart palpitations detected.\",\n      \"Document approved for Florida schools! No scary inclusive language found!\", \n      \"Phew! Your document is officially woke-free!\"\n    )\n\n    if (length(results()$keywords_found) &gt; 0) {\n      # Keywords found - show warning message\n      total_keywords &lt;- sum(results()$keyword_counts)\n      unique_keywords &lt;- length(results()$keywords_found)\n      \n      div(\n        class = \"snarky-message snarky-warning\",\n        sample(warning_messages, 1),\n        tags$br(),\n        tags$span(\n          style = \"font-size: 0.9rem; font-weight: normal;\",\n          paste0(\"Found \", total_keywords, \" occurrences of \", \n                unique_keywords, \" unique keywords\")\n        )\n      )\n    } else {\n      # No keywords found - show success message\n      div(\n        class = \"snarky-message snarky-success\",\n        sample(success_messages, 1)\n      )\n    }\n  })\n  \n  # Output: Enhanced keyword table\n  output$keyword_table &lt;- DT::renderDataTable({\n    if (is.null(results()) || length(results()$keywords_found) == 0) return(NULL)\n    \n    df &lt;- data.frame(\n      Keyword = results()$keywords_found,\n      Occurrences = results()$keyword_counts,\n      stringsAsFactors = FALSE\n    )\n    \n    # Sort by number of occurrences (descending)\n    df &lt;- df[order(-df$Occurrences), ]\n    \n    DT::datatable(\n      df,\n      options = list(\n        pageLength = 15,\n        order = list(list(1, 'desc')),\n        dom = 'tip'  # table, information, and pagination (no search)\n      ),\n      rownames = FALSE\n    ) %&gt;%\n      DT::formatStyle(\n        'Keyword',\n        fontWeight = 'bold'\n      ) %&gt;%\n      DT::formatStyle(\n        'Occurrences',\n        background = DT::styleColorBar(range(df$Occurrences), '#9ecae1'),\n        fontWeight = 'bold'\n      )\n  })\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "keywords.html",
    "href": "keywords.html",
    "title": "Keywords",
    "section": "",
    "text": "The analyzer searches for the keywords below.\nThese are basesd on Dr. Saxbe’s post on Bluesky and this EO."
  }
]